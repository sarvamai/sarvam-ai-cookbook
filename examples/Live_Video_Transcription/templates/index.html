<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Lecture Transcription - Sarvam AI</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.7.2/socket.io.js"></script>
</head>
<body>
    <div class="container">
        <!-- Header -->
        <header class="header">
            <h1>üé§ Live Lecture Transcription</h1>
            <p>Powered by Sarvam AI Streaming</p>
        </header>

        <!-- Main Content -->
        <div class="main-content">
            <!-- Video Section -->
            <div class="video-section">
                <h2>üìπ Video Player</h2>
                <video 
                    id="demoVideo" 
                    controls 
                    width="100%" 
                    height="auto"
                    crossorigin="anonymous"
                    muted="false">
                    <!-- Extended demo video with continuous speech -->
                    <source src="{{ url_for('static', filename='test2.mp4') }}" type="video/mp4">
                    <p>Your browser doesn't support HTML5 video. Please upload a video file.</p>
                </video>
                
                <!-- Video Controls -->
                <div class="controls">
                    <button id="startTranscription" class="btn-primary">Start Transcription</button>
                    <button id="stopTranscription" class="btn-secondary" disabled>Stop Transcription</button>
                    <button id="startTranslation" class="btn-primary">Start Translation</button>
                    <button id="stopTranslation" class="btn-secondary" disabled>Stop Translation</button>
                    <span id="status" class="status">Ready to transcribe</span>
                </div>
            </div>

            <!-- Transcription Section -->
            <div class="transcription-section">
                <h2>üìù Live Transcription</h2>
                <div id="transcriptionOutput" class="transcription-output">
                    <p class="placeholder">Transcriptions will appear here in real-time...</p>
                </div>
                
                <!-- Transcription Stats -->
                <div class="stats">
                    <span>Chunks processed: <span id="chunksProcessed">0</span></span>
                    <span>Current time: <span id="currentTime">00:00</span></span>
                </div>
            </div>

            <!-- Translation Section -->
            <div class="transcription-section">
                <h2>üåç Live Translation (to English)</h2>
                <div id="translationOutput" class="transcription-output">
                    <p class="placeholder">Translations will appear here in real-time...</p>
                </div>
                
                <!-- Translation Stats -->
                <div class="stats">
                    <span>Translation chunks: <span id="translationChunksProcessed">0</span></span>
                    <span>Current time: <span id="translationCurrentTime">00:00</span></span>
                </div>
            </div>
        </div>

        <!-- Footer -->
        <footer class="footer">
            <p>Demo: Real-time speech-to-text using Sarvam AI</p>
        </footer>
    </div>

    <script>
        let socket = io();
        let isRecording = false;
        let isTranslating = false;
        let mediaRecorder;
        let audioChunks = [];
        let chunkCounter = 0;
        let translationChunkCounter = 0;
        let startTime;
        let pollingInterval = null;
        let translationPollingInterval = null;
        let lastTranscriptionCount = 0;
        let lastTranslationCount = 0;
        
        // DOM elements
        const video = document.getElementById('demoVideo');
        const startBtn = document.getElementById('startTranscription');
        const stopBtn = document.getElementById('stopTranscription');
        const status = document.getElementById('status');
        const transcriptionOutput = document.getElementById('transcriptionOutput');
        const chunksCounter = document.getElementById('chunksProcessed');
        const timeDisplay = document.getElementById('currentTime');
        
        // Audio processing variables
        let audioContext, mediaStreamSource, processor;
        let isTranscribing = false;
        
        // Update status
        function updateStatus(message, type = 'info') {
            status.textContent = message;
            status.className = `status ${type}`;
        }
        
        // Format time
        function formatTime(seconds) {
            const mins = Math.floor(seconds / 60);
            const secs = Math.floor(seconds % 60);
            return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
        }
        
        // SIMPLE transcription display function
        function addTranscription(text, timestamp) {
            // Remove placeholder if present
            const placeholder = transcriptionOutput.querySelector('.placeholder');
            if (placeholder) {
                placeholder.remove();
            }
            
            // Create transcription item
            const transcriptionItem = document.createElement('div');
            transcriptionItem.className = 'transcription-item';
            transcriptionItem.innerHTML = `
                <span class="timestamp">[${formatTime(timestamp)}]</span>
                <span class="text">${text}</span>
            `;
            
            // Add to output
            transcriptionOutput.appendChild(transcriptionItem);
            transcriptionOutput.scrollTop = transcriptionOutput.scrollHeight;
        }
        
        // DIRECT WebSocket event handlers
        socket.on('connect', function() {
            console.log('‚úÖ Connected to server');
            updateStatus('Connected to transcription service', 'success');
        });
        
        socket.on('transcription_result', function(data) { 
            console.log('Received transcription:', data);
            displayTranscription(data);
        });
        
        socket.on('translation_result', function(data) { 
            console.log('Received translation:', data);
            displayTranslation(data);
        });
        
        socket.on('transcription_status', function(data) {
            console.log('Transcription status:', data.status);
        });
        
        socket.on('translation_status', function(data) {
            console.log('Translation status:', data.status);
        });
        
        socket.on('status', function(data) {
            if (data && data.message) {
                updateStatus(data.message, 'info');
            }
        });
        
        socket.on('error', function(error) {
            console.error('‚ùå Socket error:', error);
            updateStatus('Connection error', 'error');
        });
        
        socket.on('disconnect', function() {
            console.log('‚ùå Disconnected from server');
            updateStatus('Disconnected', 'error');
        });
        
        // POLLING BACKUP for transcriptions
        function startPolling() {
            pollingInterval = setInterval(() => {
                fetch('/get_transcriptions')
                    .then(response => response.json())
                    .then(data => {
                        const transcriptions = data.transcriptions || [];
                        if (transcriptions.length > lastTranscriptionCount) {
                            // Process new transcriptions
                            for (let i = lastTranscriptionCount; i < transcriptions.length; i++) {
                                const t = transcriptions[i];
                                addTranscription(t.text, t.timestamp);
                            }
                            lastTranscriptionCount = transcriptions.length;
                        }
                    })
                    .catch(error => console.error('Polling error:', error));
            }, 1000); // Poll every second
        }
        
        function stopPolling() {
            if (pollingInterval) {
                clearInterval(pollingInterval);
                pollingInterval = null;
            }
        }
        
        // Video event handlers
        video.addEventListener('timeupdate', function() {
            timeDisplay.textContent = formatTime(video.currentTime);
        });
        
        video.addEventListener('play', function() {
            socket.emit('video_control', {action: 'play', timestamp: video.currentTime});
        });
        
        video.addEventListener('pause', function() {
            socket.emit('video_control', {action: 'pause', timestamp: video.currentTime});
        });
        
        // Button event handlers
        document.getElementById('startTranscription').addEventListener('click', startTranscription);
        document.getElementById('stopTranscription').addEventListener('click', stopTranscription);
        document.getElementById('startTranslation').addEventListener('click', startTranslation);
        document.getElementById('stopTranslation').addEventListener('click', stopTranslation);
        
        // Initialize
        updateStatus('Ready to transcribe', 'info');
        
        function startTranscription() {
            if (isRecording) return;
            
            isRecording = true;
            startTime = Date.now();
            chunkCounter = 0;
            
            // Clear transcriptions first
            fetch('/clear_transcriptions');
            clearTranscriptionDisplay();
            
            // Update UI
            document.getElementById('startTranscription').disabled = true;
            document.getElementById('stopTranscription').disabled = false;
            document.getElementById('status').textContent = 'Starting transcription...';
            
            // Start recording if not already started
            if (!audioContext) {
                startRecording();
            }
            startPolling();
        }

        function stopTranscription() {
            if (!isRecording) return;
            
            isRecording = false;
            
            // Update UI
            document.getElementById('startTranscription').disabled = false;
            document.getElementById('stopTranscription').disabled = true;
            document.getElementById('status').textContent = 'Transcription stopped';
            
            // Stop recording if translation is also not active
            if (!isTranslating) {
                stopRecording();
            }
            
            if (pollingInterval) {
                clearInterval(pollingInterval);
                pollingInterval = null;
            }
        }

        function startTranslation() {
            if (isTranslating) return;
            
            isTranslating = true;
            startTime = Date.now();
            translationChunkCounter = 0;
            
            // Clear translations first
            fetch('/clear_translations');
            clearTranslationDisplay();
            
            // Update UI
            document.getElementById('startTranslation').disabled = true;
            document.getElementById('stopTranslation').disabled = false;
            document.getElementById('status').textContent = 'Starting translation...';
            
            // Start recording if not already started
            if (!audioContext) {
                startRecording();
            }
            startTranslationPolling();
        }

        function stopTranslation() {
            if (!isTranslating) return;
            
            isTranslating = false;
            
            // Update UI
            document.getElementById('startTranslation').disabled = false;
            document.getElementById('stopTranslation').disabled = true;
            document.getElementById('status').textContent = 'Translation stopped';
            
            // Stop recording if transcription is also not active
            if (!isRecording) {
                stopRecording();
            }
            
            if (translationPollingInterval) {
                clearInterval(translationPollingInterval);
                translationPollingInterval = null;
            }
        }
        
        // Resample audio to target sample rate
        function resampleAudio(audioBuffer, sourceSampleRate, targetSampleRate) {
            if (sourceSampleRate === targetSampleRate) {
                return audioBuffer;
            }
            
            const ratio = sourceSampleRate / targetSampleRate;
            const outputLength = Math.floor(audioBuffer.length / ratio);
            const output = new Int16Array(outputLength);
            
            for (let i = 0; i < outputLength; i++) {
                const sourceIndex = Math.floor(i * ratio);
                output[i] = audioBuffer[sourceIndex];
            }
            
            return output;
        }
        
        // Audio helper functions
        function encodeWAV(audioBuffer, sampleRate) {
            const length = audioBuffer.length;
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // Copy audio data
            const audioData = new Int16Array(arrayBuffer, 44);
            audioData.set(audioBuffer);
            
            return arrayBuffer;
        }
        
        function arrayBufferToBase64(buffer) {
            const uint8Array = new Uint8Array(buffer);
            let binaryString = '';
            const chunkSize = 8192; // 8KB chunks to avoid stack overflow
            
            for (let i = 0; i < uint8Array.length; i += chunkSize) {
                const chunk = uint8Array.slice(i, i + chunkSize);
                binaryString += String.fromCharCode.apply(null, chunk);
            }
            
            return btoa(binaryString);
        }

        // Send audio chunk to server
        function sendTranscriptionChunk(audioChunks, timestamp) {
            console.log('üìù sendTranscriptionChunk called with:', audioChunks.length, 'chunks');
            if (audioChunks.length === 0) {
                console.warn('üìù No transcription chunks to send!');
                return;
            }
            
            console.log(`üìù Sending transcription chunk at ${timestamp}s`);
            
            // Combine all audio chunks
            const totalLength = audioChunks.reduce((sum, chunk) => sum + chunk.length, 0);
            const combinedBuffer = new Int16Array(totalLength);
            let offset = 0;
            
            for (const chunk of audioChunks) {
                combinedBuffer.set(chunk, offset);
                offset += chunk.length;
            }
            
            console.log('üìù Combined buffer length:', combinedBuffer.length);
            
            // Resample from 44.1kHz to 16kHz
            const originalSampleRate = audioContext.sampleRate;
            const targetSampleRate = 16000;
            const resampledBuffer = resampleAudio(combinedBuffer, originalSampleRate, targetSampleRate);
            
            console.log('üìù Resampled buffer length:', resampledBuffer.length);
            
            // Create WAV file
            const wavBuffer = encodeWAV(resampledBuffer, targetSampleRate);
            const base64Audio = arrayBufferToBase64(wavBuffer);
            
            console.log('üìù Base64 audio length:', base64Audio.length);
            
            // Send via WebSocket
            const chunkData = {
                audio: base64Audio,
                timestamp: timestamp,
                chunkName: `chunk_${++chunkCounter}`
            };
            
            console.log(`üìù Emitting audio_chunk: ${chunkData.chunkName}, size: ${base64Audio.length} chars`);
            socket.emit('audio_chunk', chunkData);
            
            // Update UI
            document.getElementById('chunksProcessed').textContent = chunkCounter;
            document.getElementById('currentTime').textContent = formatTime(timestamp);
        }

        // Send translation chunk to server
        function sendTranslationChunk(audioChunks, timestamp) {
            console.log('üåç sendTranslationChunk called with:', audioChunks.length, 'chunks');
            if (audioChunks.length === 0) {
                console.warn('üåç No translation chunks to send!');
                return;
            }
            
            console.log(`üåç Sending translation chunk at ${timestamp}s`);
            
            // Combine all audio chunks
            const totalLength = audioChunks.reduce((sum, chunk) => sum + chunk.length, 0);
            const combinedBuffer = new Int16Array(totalLength);
            let offset = 0;
            
            for (const chunk of audioChunks) {
                combinedBuffer.set(chunk, offset);
                offset += chunk.length;
            }
            
            console.log('üåç Combined buffer length:', combinedBuffer.length);
            
            // Resample from 44.1kHz to 16kHz
            const originalSampleRate = audioContext.sampleRate;
            const targetSampleRate = 16000;
            const resampledBuffer = resampleAudio(combinedBuffer, originalSampleRate, targetSampleRate);
            
            console.log('üåç Resampled buffer length:', resampledBuffer.length);
            
            // Create WAV file
            const wavBuffer = encodeWAV(resampledBuffer, targetSampleRate);
            const base64Audio = arrayBufferToBase64(wavBuffer);
            
            console.log('üåç Base64 audio length:', base64Audio.length);
            
            // Send via WebSocket
            const chunkData = {
                audio: base64Audio,
                timestamp: timestamp,
                chunkName: `chunk_${++translationChunkCounter}`
            };
            
            console.log(`üåç Emitting translation_chunk: ${chunkData.chunkName}, size: ${base64Audio.length} chars`);
            socket.emit('translation_chunk', chunkData);
            
            // Update UI
            document.getElementById('translationChunksProcessed').textContent = translationChunkCounter;
            document.getElementById('translationCurrentTime').textContent = formatTime(timestamp);
        }
        
        // Helper functions for recording
        async function startRecording() {
            try {
                console.log('üéôÔ∏è Starting audio recording...');
                
                // Ensure video is playing and not muted
                video.muted = false;
                video.volume = 1.0;
                
                // Force play with audio
                if (video.paused) {
                    await video.play();
                }
                
                console.log('üìπ Video state:', {
                    paused: video.paused,
                    muted: video.muted,
                    volume: video.volume,
                    currentTime: video.currentTime
                });
                
                // Create audio context to capture video audio
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('üîä Audio context created, sample rate:', audioContext.sampleRate);
                
                // Create media stream from video
                const stream = video.captureStream();
                const audioTracks = stream.getAudioTracks();
                console.log('üéµ Audio tracks:', audioTracks.length);
                
                if (audioTracks.length === 0) {
                    throw new Error('No audio tracks found in video stream!');
                }
                
                mediaStreamSource = audioContext.createMediaStreamSource(stream);
                
                // Create script processor for audio chunks
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                console.log('‚öôÔ∏è Audio processor created');
                
                let audioChunks = [];
                let chunkDuration = 3000; // 3 seconds
                let lastChunkTime = Date.now();
                let lastTranslationTime = Date.now(); // Added for translation timing
                
                processor.onaudioprocess = function(event) {
                    if (!isRecording && !isTranslating) return;
                    
                    const inputBuffer = event.inputBuffer;
                    const audioData = inputBuffer.getChannelData(0);
                    
                    // Check for actual audio data
                    let maxAmplitude = 0;
                    for (let i = 0; i < audioData.length; i++) {
                        maxAmplitude = Math.max(maxAmplitude, Math.abs(audioData[i]));
                    }
                    
                    // Convert to Int16Array
                    const int16Array = new Int16Array(audioData.length);
                    for (let i = 0; i < audioData.length; i++) {
                        int16Array[i] = audioData[i] * 32767;
                    }
                    
                    audioChunks.push(int16Array);
                    
                    const currentTime = Date.now();
                    
                    // Send transcription chunk every 3 seconds
                    if (isRecording && currentTime - lastChunkTime >= 3000) {
                        console.log('‚è∞ 3 seconds passed, processing transcription chunk...');
                        console.log('üìä Audio stats:', {
                            chunks: audioChunks.length,
                            maxAmplitude: maxAmplitude.toFixed(4),
                            isRecording: isRecording,
                            isTranslating: isTranslating
                        });
                        
                        if (audioChunks.length > 0) {
                            console.log('üìù Sending transcription chunk...');
                            const chunksToSend = [...audioChunks];
                            audioChunks = []; // Clear immediately after copying
                            sendTranscriptionChunk(chunksToSend, video.currentTime);
                        }
                        
                        lastChunkTime = currentTime;
                    }
                    
                    // Send translation chunk every 2 seconds
                    if (isTranslating && currentTime - lastTranslationTime >= 2000) {
                        console.log('‚è∞ 2 seconds passed, processing translation chunk...');
                        
                        if (audioChunks.length > 0) {
                            console.log('üåç Sending translation chunk...');
                            const chunksToSend = [...audioChunks];
                            audioChunks = []; // Clear immediately after copying
                            sendTranslationChunk(chunksToSend, video.currentTime);
                        }
                        
                        lastTranslationTime = currentTime;
                    }
                };
                
                // Connect audio nodes
                mediaStreamSource.connect(processor);
                processor.connect(audioContext.destination);
                
                console.log('‚úÖ Audio recording setup complete!');
                
            } catch (error) {
                console.error('‚ùå Error starting recording:', error);
            }
        }
        
        function stopRecording() {
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            if (mediaStreamSource) {
                mediaStreamSource.disconnect();
                mediaStreamSource = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
        }
        
        // Display functions
        function displayTranscription(data) {
            if (data && data.text && data.text.trim()) {
                const output = document.getElementById('transcriptionOutput');
                const placeholder = output.querySelector('.placeholder');
                if (placeholder) placeholder.remove();
                
                const transcriptionElement = document.createElement('div');
                transcriptionElement.className = 'transcription-item';
                transcriptionElement.innerHTML = `
                    <span class="timestamp">[${formatTime(data.timestamp || 0)}]</span>
                    <span class="text">${data.text}</span>
                `;
                
                output.appendChild(transcriptionElement);
                output.scrollTop = output.scrollHeight;
            }
        }
        
        function displayTranslation(data) {
            if (data && data.text && data.text.trim()) {
                const output = document.getElementById('translationOutput');
                const placeholder = output.querySelector('.placeholder');
                if (placeholder) placeholder.remove();
                
                const translationElement = document.createElement('div');
                translationElement.className = 'transcription-item';
                translationElement.innerHTML = `
                    <span class="timestamp">[${formatTime(data.timestamp || 0)}]</span>
                    <span class="text">${data.text}</span>
                `;
                
                output.appendChild(translationElement);
                output.scrollTop = output.scrollHeight;
            }
        }
        
        function clearTranscriptionDisplay() {
            const output = document.getElementById('transcriptionOutput');
            output.innerHTML = '<p class="placeholder">Transcriptions will appear here in real-time...</p>';
            document.getElementById('chunksProcessed').textContent = '0';
            document.getElementById('currentTime').textContent = '00:00';
        }
        
        function clearTranslationDisplay() {
            const output = document.getElementById('translationOutput');
            output.innerHTML = '<p class="placeholder">Translations will appear here in real-time...</p>';
            document.getElementById('translationChunksProcessed').textContent = '0';
            document.getElementById('translationCurrentTime').textContent = '00:00';
        }
        
        // Translation polling
        function startTranslationPolling() {
            translationPollingInterval = setInterval(() => {
                fetch('/get_translations')
                    .then(response => response.json())
                    .then(data => {
                        if (data.translations && data.translations.length > lastTranslationCount) {
                            const newTranslations = data.translations.slice(lastTranslationCount);
                            newTranslations.forEach(translation => displayTranslation(translation));
                            lastTranslationCount = data.translations.length;
                        }
                    })
                    .catch(error => console.error('Translation polling error:', error));
            }, 1000);
        }
    </script>
</body>
</html> 