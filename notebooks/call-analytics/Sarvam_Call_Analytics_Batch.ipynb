{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFQhccgldqvj"
      },
      "source": [
        "Installing all the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVx5k55KQVrJ"
      },
      "outputs": [],
      "source": [
        "!pip install sarvamai\n",
        "print(\"Installation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht5Ft6GWd_y8"
      },
      "source": [
        "Setting up all the essential modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TrFqoqtNQXlj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional\n",
        "from pydub import AudioSegment\n",
        "from sarvamai import SarvamAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vYMt1DFeVF8"
      },
      "source": [
        "Set your output location for .json files and .txt files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wil5v20vQX66"
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIR = \"outputs\"\n",
        "Path(OUTPUT_DIR).mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tchfAl1herxQ"
      },
      "source": [
        "Breakdown of each function in the CallAnalytics class\n",
        "\n",
        "\n",
        "1. split_audio - splits a long audio file into smaller chunks if its duration exceeds 1 hour because Batch API can process 1hr long audio files\n",
        "\n",
        "2. process_audio_files - Creates a transcription job using Sarvam's STT BATCH API, waits for job completion, downloads and parses transcription output & calls analyze_transcription() on the parsed conversation\n",
        "\n",
        "3. _parse_transcriptions- Reads downloaded JSON transcription files, extracts speaker-wise lines, writes a .txt file with clean conversation format: SPEAKER: text, calculates total speaking time per speaker (from timestamps) & writes a timing JSON file.\n",
        "\n",
        "*   _timing.json- tracks the total speaking time per speaker in seconds. Beneficial in identifying dominant speaker and helps in monitoring Agent Talk-Time vs. Listening Time.\n",
        "\n",
        "Here's a breakdown of all the things that we included to make the best analysis possible\n",
        "\n",
        "*   Diarization assigns speaker labels, linking each line of text to the speaker who said it. It helps maintain speaker tracking, enables sentiment analysis for each speaker, and most importantly, distinguishes between the agent and the customer.\n",
        "*   Why didn’t we just join all transcripts into one large chunk?\n",
        "Maintaining the chronological, speaker-wise flow is crucial in call analysis. That’s why we create a separate conversation.txt file, which preserves the entire transcribed call in its original order. This file is passed into all function calls to enable better contextual understanding, deeper insights, and more accurate interpretation by LLMs.\n",
        "\n",
        "4. analyze_transcription- Reads the conversation.txt file with the full conversation and sends it to Sarvam LLM with a detailed analysis prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0Z7269MQYOs"
      },
      "outputs": [],
      "source": [
        "def split_audio(audio_path: str, chunk_duration_ms: int = 60 * 60 * 1000) -> List[AudioSegment]:\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "    return [audio[i:i + chunk_duration_ms] for i in range(0, len(audio), chunk_duration_ms)] if len(audio) > chunk_duration_ms else [audio]\n",
        "\n",
        "\n",
        "class CallAnalytics:\n",
        "    def __init__(self, client):\n",
        "        self.client = client\n",
        "        self.transcriptions = {}  # file_stem -> { entries: [...], conversation_path: str }\n",
        "\n",
        "    def process_audio_files(self, audio_paths: List[str]) -> Dict[str, str]:\n",
        "        if not audio_paths:\n",
        "            print(\"No audio files provided\")\n",
        "            return {}\n",
        "\n",
        "        print(f\"Processing {len(audio_paths)} audio files...\")\n",
        "\n",
        "        try:\n",
        "            job = client.speech_to_text_translate_job.create_job(\n",
        "                model=\"saaras:v2.5\",\n",
        "                with_diarization=True,\n",
        "            )\n",
        "            job.upload_files(file_paths=audio_paths)\n",
        "            job.start()\n",
        "\n",
        "            print(\"Waiting for transcription to complete...\")\n",
        "            job.wait_until_complete()\n",
        "\n",
        "            if job.is_failed():\n",
        "                print(\"Transcription failed!\")\n",
        "                return {}\n",
        "\n",
        "            output_dir = Path(f\"{OUTPUT_DIR}/transcriptions_{job.job_id}\")\n",
        "            output_dir.mkdir(parents=True, exist_ok=True)\n",
        "            job.download_outputs(output_dir=str(output_dir))\n",
        "            json_files = list(output_dir.glob(\"*.json\"))\n",
        "            if not json_files:\n",
        "              raise FileNotFoundError(f\"No .json transcription files found in {output_dir}.\")\n",
        "\n",
        "            transcriptions = self._parse_transcriptions(output_dir)\n",
        "            self.transcriptions.update(transcriptions)\n",
        "\n",
        "            print(f\"Successfully transcribed {len(transcriptions)} files!\")\n",
        "\n",
        "            for file_name, data in transcriptions.items():\n",
        "                self.analyze_transcription(data[\"conversation_path\"], output_dir, file_name)\n",
        "\n",
        "            return transcriptions\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing audio files: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def _parse_transcriptions(self, output_dir: Path) -> Dict[str, dict]:\n",
        "        transcriptions = {}\n",
        "        for json_file in output_dir.glob(\"*.json\"):\n",
        "            try:\n",
        "                with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                diarized = data.get(\"diarized_transcript\", {}).get(\"entries\")\n",
        "                speaker_times = {}\n",
        "                lines = []\n",
        "\n",
        "                if diarized:\n",
        "                    for entry in diarized:\n",
        "                        speaker = entry[\"speaker_id\"]\n",
        "                        text = entry[\"transcript\"]\n",
        "                        lines.append(f\"{speaker}: {text}\")\n",
        "\n",
        "                        start = entry.get(\"start_time_seconds\")\n",
        "                        end = entry.get(\"end_time_seconds\")\n",
        "                        if start is not None and end is not None:\n",
        "                            duration = end - start\n",
        "                            speaker_times[speaker] = speaker_times.get(speaker, 0.0) + duration\n",
        "                else:\n",
        "                    lines = [f\"UNKNOWN: {data.get('transcript', '')}\"]\n",
        "\n",
        "                # Save conversation without timestamps\n",
        "                conversation_text = \"\\n\".join(lines)\n",
        "                txt_path = output_dir / f\"{json_file.stem}_conversation.txt\"\n",
        "                with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(conversation_text)\n",
        "\n",
        "                # Save speaker timing if available\n",
        "                timing_path = None\n",
        "                if speaker_times:\n",
        "                    timing_path = output_dir / f\"{json_file.stem}_timing.json\"\n",
        "                    with open(timing_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        json.dump(speaker_times, f, indent=2)\n",
        "\n",
        "                transcriptions[json_file.stem] = {\n",
        "                    \"entries\": diarized or [],\n",
        "                    \"conversation_path\": str(txt_path),\n",
        "                    \"timing_path\": str(timing_path) if timing_path else None\n",
        "                }\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing {json_file}: {e}\")\n",
        "        return transcriptions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def analyze_transcription(self, conversation_path: str, output_dir: Path, file_name: str) -> Dict:\n",
        "        try:\n",
        "            with open(conversation_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                transcription = f.read()\n",
        "\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": \"You are a call analytics expert working for a company's support operations team. Your job is to understand customer calls end-to-end and provide structured insights to improve customer experience and agent effectiveness.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"\"\"\n",
        "                                                Analyze this call transcription thoroughly from start to finish.\n",
        "\n",
        "                                                TRANSCRIPTION:\n",
        "                                                {transcription}\n",
        "\n",
        "                                                Please answer the following:\n",
        "\n",
        "                                                1. Identify which speaker is the **customer** and which one is the **agent**.\n",
        "                                                2. Determine if the customer is a **new/potential customer** or an **existing customer**.\n",
        "                                                3. What **problem, query, or doubt** did the customer raise at the beginning?\n",
        "                                                4. What **services/products** was the customer inquiring about or facing issues with?\n",
        "                                                5. How did the agent respond to and resolve the issue throughout the call?\n",
        "                                                6. Was the **customer satisfied** at the end of the call?\n",
        "                                                7. Did the customer express any **emotions or sentiments** (positive, negative, or neutral)?\n",
        "                                                8. Were there any mentions of **competitors**, or any opportunities for **upselling or cross-selling**?\n",
        "                                                9. Summarize the **resolution** and whether it was successful.\n",
        "\n",
        "                                                Provide your answer in a clear, structured format with section headings and bullet points.\n",
        "                                                \"\"\"},\n",
        "            ]\n",
        "            response = self.client.chat.completions(messages=messages)\n",
        "            analysis = response.choices[0].message.content\n",
        "\n",
        "            analysis_path = output_dir / f\"{file_name}_analysis.txt\"\n",
        "            with open(analysis_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(analysis.strip())\n",
        "\n",
        "            print(f\"Analysis saved to {analysis_path}\")\n",
        "            return {\"file_name\": file_name, \"analysis_path\": str(analysis_path)}\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error analyzing transcription: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            return {\"file_name\": file_name, \"error\": error_msg, \"timestamp\": datetime.now().isoformat()}\n",
        "\n",
        "    def answer_question(self, question: str, output_dir: Optional[Path] = None) -> None:\n",
        "        for file_name, data in self.transcriptions.items():\n",
        "            try:\n",
        "                with open(data[\"conversation_path\"], \"r\", encoding=\"utf-8\") as f:\n",
        "                    transcription = f.read()\n",
        "\n",
        "                prompt = f\"Based on this call transcription, answer the question below:\\n\\nTRANSCRIPTION:\\n{transcription}\\n\\nQUESTION: {question}\"\n",
        "\n",
        "                messages = [\n",
        "                    {\"role\": \"system\", \"content\": \"\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt},\n",
        "                ]\n",
        "                response = self.client.chat.completions(messages=messages)\n",
        "                answer = response.choices[0].message.content\n",
        "\n",
        "                q_hash = hashlib.sha1(question.encode()).hexdigest()[:6]\n",
        "                path = Path(data[\"conversation_path\"]).parent / f\"{file_name}_question_{q_hash}.txt\"\n",
        "                with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(f\"Question: {question}\\n\\nAnswer:\\n{answer}\")\n",
        "                print(f\"Answer saved to {path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error answering question for {file_name}: {e}\")\n",
        "\n",
        "    def get_summary(self, output_dir: Optional[Path] = None) -> None:\n",
        "        output_dir = output_dir or Path(OUTPUT_DIR)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        summary_path = output_dir / f\"summary_{timestamp}.txt\"\n",
        "\n",
        "        try:\n",
        "            with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(\"CALL ANALYTICS SUMMARY REPORT\\n\")\n",
        "                f.write(\"=\" * 60 + \"\\n\")\n",
        "                f.write(f\"Generated: {datetime.now()}\\n\")\n",
        "                f.write(f\"Total Calls: {len(self.transcriptions)}\\n\")\n",
        "                f.write(\"=\" * 60 + \"\\n\\n\")\n",
        "\n",
        "                for file_name, data in self.transcriptions.items():\n",
        "                    analysis_file = Path(data[\"conversation_path\"]).parent / f\"{file_name}_analysis.txt\"\n",
        "                    if not analysis_file.exists():\n",
        "                        print(f\"Analysis file not found for {file_name}, skipping.\")\n",
        "                        continue\n",
        "\n",
        "                    with open(analysis_file, \"r\", encoding=\"utf-8\") as af:\n",
        "                        analysis_text = af.read()\n",
        "\n",
        "                    summary_prompt = f\"\"\"\n",
        "                    Based on this call analysis, summarize each of the following in 2-3 words:\n",
        "\n",
        "                    {analysis_text}\n",
        "\n",
        "                    1. Customer & Agent\n",
        "                    2. Customer Type\n",
        "                    3. Main Issue\n",
        "                    4. Service Discussed\n",
        "                    5. Agent's Response\n",
        "                    6. Customer Satisfaction\n",
        "                    7. Sentiment\n",
        "                    8. Competitor or Upsell\n",
        "                    9. Resolution\n",
        "                    \"\"\"\n",
        "\n",
        "                    messages = [\n",
        "                        {\"role\": \"system\", \"content\": \"You are a call analytics summarizing expert. Provide concise and clear answers to each point \"},\n",
        "                        {\"role\": \"user\", \"content\": summary_prompt},\n",
        "                    ]\n",
        "                    response = self.client.chat.completions(messages=messages)\n",
        "                    concise_summary = response.choices[0].message.content.strip()\n",
        "\n",
        "                    f.write(f\"Call File: {file_name}\\n\")\n",
        "                    f.write(\"-\" * 30 + \"\\n\")\n",
        "                    f.write(f\"{concise_summary}\\n\\n\")\n",
        "\n",
        "            print(f\"Summary saved to {summary_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error writing summary: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkqc7ItPpB9p"
      },
      "source": [
        "Final code block runs the full call analytics workflow-it transcribes the audio, analyzes the conversation using an LLM, and answers a specific user question. It then generates a concise summary of the call and saves all outputs in structured text files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WDclBnuQYd0"
      },
      "outputs": [],
      "source": [
        "client = SarvamAI(api_subscription_key=\"YOUR_SARVAM_API_KEY\")\n",
        "\n",
        "analytics = CallAnalytics(client=client)\n",
        "\n",
        "audio_path = \"path/to/your/audio/file.mp3\"\n",
        "\n",
        "analytics.process_audio_files([audio_path])\n",
        "\n",
        "analytics.answer_question(\"Add your question here\")\n",
        "\n",
        "analytics.get_summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
